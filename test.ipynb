{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "baee7639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from hermes.app import HermesApp\n",
    "from hermes.ui_agent import LLMReasoningCapture\n",
    "# Initialize the reasoning capture handler\n",
    "reasoning_capture = LLMReasoningCapture()\n",
    "\n",
    "# Attach to relevant loggers\n",
    "for logger_name in ['root', 'hermes']:\n",
    "    logging.getLogger(logger_name).addHandler(reasoning_capture)\n",
    "    \n",
    "hermes_app = HermesApp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96b173b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       id    route warehouse  delivery_time  delay_minutes      delay_reason  \\\n",
       " 0       1  Route C       WH2           4.88             51     Customs Delay   \n",
       " 1       2  Route A       WH4           4.77             45       Driver Rest   \n",
       " 2       3  Route C       WH4           5.31            113           Traffic   \n",
       " 3       4  Route B       WH4           5.83             32   Minor Breakdown   \n",
       " 4       5  Route C       WH4           6.13            120           Traffic   \n",
       " ..    ...      ...       ...            ...            ...               ...   \n",
       " 995   996  Route B       WH2           5.60            118           Weather   \n",
       " 996   997  Route E       WH4           5.00             83       Driver Rest   \n",
       " 997   998  Route B       WH4           5.45             52       Driver Rest   \n",
       " 998   999  Route E       WH4           5.61            117           Traffic   \n",
       " 999  1000  Route B       WH3           5.52            105  Mechanical Issue   \n",
       " \n",
       "           date  on_time  \n",
       " 0   2024-01-02        0  \n",
       " 1   2024-01-03        0  \n",
       " 2   2024-01-04        0  \n",
       " 3   2024-01-05        0  \n",
       " 4   2024-01-06        0  \n",
       " ..         ...      ...  \n",
       " 995 2024-09-23        0  \n",
       " 996 2024-09-24        0  \n",
       " 997 2024-09-25        0  \n",
       " 998 2024-09-26        0  \n",
       " 999 2024-09-27        0  \n",
       " \n",
       " [1000 rows x 8 columns],\n",
       " 'âœ… Loaded 1000 shipment records')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hermes_app.get_csv_files()\n",
    "hermes_app.load_data(None, None, selected_file=\"data/shipments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba2a3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = hermes_app._handle_general_chat(\"Show me the distribution of shipment delays.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b556b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.metadata[\"raw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb0b7e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = hermes_app._handle_stats_chat(\"Show me the distribution of shipment delays.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b2514cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandas as pd\\nsql_query = \"\"\"\\nSELECT \\n    delay_reason, \\n    COUNT(*) AS count\\nFROM \\n    table_6619b1d3d4c59fcb9f82845d59178bfd\\nGROUP BY \\n    delay_reason\\nORDER BY \\n    count DESC;\\n\"\"\"\\ndelay_distribution_df = execute_sql_query(sql_query)\\nresult = {\\'type\\': \\'dataframe\\', \\'value\\': delay_distribution_df}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.raw_result.last_code_executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfe83b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'timestamp': '2025-11-09T23:39:02.861362',\n",
       "  'elapsed_ms': 0,\n",
       "  'level': 'WARNING',\n",
       "  'logger': 'semantic',\n",
       "  'message': \"Failed to register semantic dataset: create() got an unexpected keyword argument 'name'\",\n",
       "  'step': 'other'},\n",
       " {'timestamp': '2025-11-09T23:39:02.861362',\n",
       "  'elapsed_ms': 0,\n",
       "  'level': 'WARNING',\n",
       "  'logger': 'semantic',\n",
       "  'message': \"Failed to register semantic dataset: create() got an unexpected keyword argument 'name'\",\n",
       "  'step': 'other'},\n",
       " {'timestamp': '2025-11-09T23:39:02.866478',\n",
       "  'elapsed_ms': 5,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'app',\n",
       "  'message': 'Loaded 1000 records from data/shipments.csv',\n",
       "  'step': 'other'},\n",
       " {'timestamp': '2025-11-09T23:39:02.866478',\n",
       "  'elapsed_ms': 5,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'app',\n",
       "  'message': 'Loaded 1000 records from data/shipments.csv',\n",
       "  'step': 'other'},\n",
       " {'timestamp': '2025-11-09T23:39:08.175502',\n",
       "  'elapsed_ms': 5314,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'logger',\n",
       "  'message': 'Running PandasAI with litellm LLM...',\n",
       "  'step': 'other'},\n",
       " {'timestamp': '2025-11-09T23:39:08.220860',\n",
       "  'elapsed_ms': 5359,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'logger',\n",
       "  'message': 'Prompt ID: d11926b0-4673-4493-912e-24f82650f906',\n",
       "  'step': 'other'},\n",
       " {'timestamp': '2025-11-09T23:39:10.443394',\n",
       "  'elapsed_ms': 7582,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'logger',\n",
       "  'message': 'Cleaning the generated code...',\n",
       "  'step': 'other'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_capture.categorized_steps['other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9ab054b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'other': [{'timestamp': '2025-11-09T23:39:02.861362',\n",
       "   'elapsed_ms': 0,\n",
       "   'level': 'WARNING',\n",
       "   'logger': 'semantic',\n",
       "   'message': \"Failed to register semantic dataset: create() got an unexpected keyword argument 'name'\",\n",
       "   'step': 'other'},\n",
       "  {'timestamp': '2025-11-09T23:39:02.861362',\n",
       "   'elapsed_ms': 0,\n",
       "   'level': 'WARNING',\n",
       "   'logger': 'semantic',\n",
       "   'message': \"Failed to register semantic dataset: create() got an unexpected keyword argument 'name'\",\n",
       "   'step': 'other'},\n",
       "  {'timestamp': '2025-11-09T23:39:02.866478',\n",
       "   'elapsed_ms': 5,\n",
       "   'level': 'INFO',\n",
       "   'logger': 'app',\n",
       "   'message': 'Loaded 1000 records from data/shipments.csv',\n",
       "   'step': 'other'},\n",
       "  {'timestamp': '2025-11-09T23:39:02.866478',\n",
       "   'elapsed_ms': 5,\n",
       "   'level': 'INFO',\n",
       "   'logger': 'app',\n",
       "   'message': 'Loaded 1000 records from data/shipments.csv',\n",
       "   'step': 'other'},\n",
       "  {'timestamp': '2025-11-09T23:39:08.175502',\n",
       "   'elapsed_ms': 5314,\n",
       "   'level': 'INFO',\n",
       "   'logger': 'logger',\n",
       "   'message': 'Running PandasAI with litellm LLM...',\n",
       "   'step': 'other'},\n",
       "  {'timestamp': '2025-11-09T23:39:08.220860',\n",
       "   'elapsed_ms': 5359,\n",
       "   'level': 'INFO',\n",
       "   'logger': 'logger',\n",
       "   'message': 'Prompt ID: d11926b0-4673-4493-912e-24f82650f906',\n",
       "   'step': 'other'},\n",
       "  {'timestamp': '2025-11-09T23:39:10.443394',\n",
       "   'elapsed_ms': 7582,\n",
       "   'level': 'INFO',\n",
       "   'logger': 'logger',\n",
       "   'message': 'Cleaning the generated code...',\n",
       "   'step': 'other'}],\n",
       " 'query_understanding': [{'timestamp': '2025-11-09T23:39:08.105074',\n",
       "   'elapsed_ms': 5243,\n",
       "   'level': 'INFO',\n",
       "   'logger': 'app',\n",
       "   'message': 'Handling statistics request (typed)',\n",
       "   'step': 'query_understanding'},\n",
       "  {'timestamp': '2025-11-09T23:39:08.105074',\n",
       "   'elapsed_ms': 5243,\n",
       "   'level': 'INFO',\n",
       "   'logger': 'app',\n",
       "   'message': 'Handling statistics request (typed)',\n",
       "   'step': 'query_understanding'},\n",
       "  {'timestamp': '2025-11-09T23:39:08.107831',\n",
       "   'elapsed_ms': 5246,\n",
       "   'level': 'INFO',\n",
       "   'logger': 'logger',\n",
       "   'message': 'Question: <TIME_CONTEXT>Current date: 2024-12-30</TIME_CONTEXT>\\nShow me the distribution of shipment delays. /no_think',\n",
       "   'step': 'query_understanding'}],\n",
       " 'code_generation': [{'timestamp': '2025-11-09T23:39:08.241413',\n",
       "   'elapsed_ms': 5380,\n",
       "   'level': 'INFO',\n",
       "   'logger': 'logger',\n",
       "   'message': 'Generating new code...',\n",
       "   'step': 'code_generation'},\n",
       "  {'timestamp': '2025-11-09T23:39:08.270684',\n",
       "   'elapsed_ms': 5409,\n",
       "   'level': 'INFO',\n",
       "   'logger': 'logger',\n",
       "   'message': 'Using Prompt: <tables>\\n\\n<table dialect=\"duckdb\" table_name=\"table_6619b1d3d4c59fcb9f82845d59178bfd\" columns=\"[{\"name\": \"id\", \"type\": \"integer\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"route\", \"type\": \"string\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"warehouse\", \"type\": \"string\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"delivery_time\", \"type\": \"float\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"delay_minutes\", \"type\": \"integer\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"delay_reason\", \"type\": \"string\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"date\", \"type\": \"datetime\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"on_time\", \"type\": \"integer\", \"description\": null, \"expression\": null, \"alias\": null}]\" dimensions=\"1000x8\">\\nid,route,warehouse,delivery_time,delay_minutes,delay_reason,date,on_time\\n1,Route C,WH2,4.88,51,Customs Delay,2024-01-02,0\\n2,Route A,WH4,4.77,45,Driver Rest,2024-01-03,0\\n3,Route C,WH4,5.31,113,Traffic,2024-01-04,0\\n4,Route B,WH4,5.83,32,Minor Breakdown,2024-01-05,0\\n5,Route C,WH4,6.13,120,Traffic,2024-01-06,0\\n</table>\\n\\n\\n</tables>\\n\\nYou are already provided with the following functions that you can call:\\n<function>\\ndef execute_sql_query(sql_query: str) -> pd.Dataframe\\n    \"\"\"This method connects to the database, executes the sql query and returns the dataframe\"\"\"\\n</function>\\n\\n\\nUpdate this initial code:\\n```python\\n# TODO: import the required dependencies\\nimport pandas as pd\\n\\n# Write code here\\n\\n# Declare result var: \\ntype (possible values \"string\", \"number\", \"dataframe\", \"plot\"). Examples: { \"type\": \"string\", \"value\": f\"The highest salary is {highest_salary}.\" } or { \"type\": \"number\", \"value\": 125 } or { \"type\": \"dataframe\", \"value\": pd.DataFrame({...}) } or { \"type\": \"plot\", \"value\": \"temp_chart.png\" }\\n\\n```\\n\\n\\n\\n### QUERY\\n <TIME_CONTEXT>Current date: 2024-12-30</TIME_CONTEXT>\\nShow me the distribution of shipment delays. /no_think\\n\\nAt the end, declare \"result\" variable as a dictionary of type and value.\\n\\n\\nGenerate python code and return full updated code:\\n\\n### Note: Use only relevant table for query and do aggregation, sorting, joins and grouby through sql query',\n",
       "   'step': 'code_generation'},\n",
       "  {'timestamp': '2025-11-09T23:39:10.358332',\n",
       "   'elapsed_ms': 7496,\n",
       "   'level': 'INFO',\n",
       "   'logger': 'logger',\n",
       "   'message': 'Code Generated:\\n# TODO: import the required dependencies\\nimport pandas as pd\\n\\n# Write code here\\nsql_query = \"\"\"\\nSELECT \\n    delay_reason, \\n    COUNT(*) AS count\\nFROM \\n    table_6619b1d3d4c59fcb9f82845d59178bfd\\nGROUP BY \\n    delay_reason\\nORDER BY \\n    count DESC;\\n\"\"\"\\n\\n# Execute the SQL query\\ndelay_distribution_df = execute_sql_query(sql_query)\\n\\n# Declare result var: \\nresult = {\\n    \"type\": \"dataframe\",\\n    \"value\": delay_distribution_df\\n}',\n",
       "   'step': 'code_generation'}],\n",
       " 'code_validation': [{'timestamp': '2025-11-09T23:39:10.393831',\n",
       "   'elapsed_ms': 7532,\n",
       "   'level': 'INFO',\n",
       "   'logger': 'logger',\n",
       "   'message': 'Validating code requirements...',\n",
       "   'step': 'code_validation'},\n",
       "  {'timestamp': '2025-11-09T23:39:10.421342',\n",
       "   'elapsed_ms': 7559,\n",
       "   'level': 'INFO',\n",
       "   'logger': 'logger',\n",
       "   'message': 'Code validation successful.',\n",
       "   'step': 'code_validation'}],\n",
       " 'code_execution': [{'timestamp': '2025-11-09T23:39:10.464332',\n",
       "   'elapsed_ms': 7602,\n",
       "   'level': 'INFO',\n",
       "   'logger': 'logger',\n",
       "   'message': 'Executing code: import pandas as pd\\nsql_query = \"\"\"\\nSELECT \\n    delay_reason, \\n    COUNT(*) AS count\\nFROM \\n    table_6619b1d3d4c59fcb9f82845d59178bfd\\nGROUP BY \\n    delay_reason\\nORDER BY \\n    count DESC;\\n\"\"\"\\ndelay_distribution_df = execute_sql_query(sql_query)\\nresult = {\\'type\\': \\'dataframe\\', \\'value\\': delay_distribution_df}',\n",
       "   'step': 'code_execution'}],\n",
       " 'response_generation': [{'timestamp': '2025-11-09T23:39:10.508636',\n",
       "   'elapsed_ms': 7647,\n",
       "   'level': 'INFO',\n",
       "   'logger': 'logger',\n",
       "   'message': 'Response generated successfully.',\n",
       "   'step': 'response_generation'}]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_capture.categorized_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5387f08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Generation Step (Duration: 2281ms):\n",
      "Using Prompt: \n",
      "```html\n",
      "<tables>\n",
      "\n",
      "<table dialect=\"duckdb\" table_name=\"table_6619b1d3d4c59fcb9f82845d59178bfd\" columns=\"[{\"name\": \"id\", \"type\": \"integer\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"route\", \"type\": \"string\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"warehouse\", \"type\": \"string\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"delivery_time\", \"type\": \"float\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"delay_minutes\", \"type\": \"integer\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"delay_reason\", \"type\": \"string\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"date\", \"type\": \"datetime\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"on_time\", \"type\": \"integer\", \"description\": null, \"expression\": null, \"alias\": null}]\" dimensions=\"1000x8\">\n",
      "id,route,warehouse,delivery_time,delay_minutes,delay_reason,date,on_time\n",
      "1,Route C,WH2,4.88,51,Customs Delay,2024-01-02,0\n",
      "2,Route A,WH4,4.77,45,Driver Rest,2024-01-03,0\n",
      "3,Route C,WH4,5.31,113,Traffic,2024-01-04,0\n",
      "4,Route B,WH4,5.83,32,Minor Breakdown,2024-01-05,0\n",
      "5,Route C,WH4,6.13,120,Traffic,2024-01-06,0\n",
      "</table>\n",
      "\n",
      "\n",
      "</tables>\n",
      "\n",
      "You are already provided with the following functions that you can call:\n",
      "<function>\n",
      "def execute_sql_query(sql_query: str) -> pd.Dataframe\n",
      "    \"\"\"This method connects to the database, executes the sql query and returns the dataframe\"\"\"\n",
      "</function>\n",
      "\n",
      "\n",
      "Update this initial code:\n",
      "```python\n",
      "# TODO: import the required dependencies\n",
      "import pandas as pd\n",
      "\n",
      "# Write code here\n",
      "\n",
      "# Declare result var: \n",
      "type (possible values \"string\", \"number\", \"dataframe\", \"plot\"). Examples: { \"type\": \"string\", \"value\": f\"The highest salary is {highest_salary}.\" } or { \"type\": \"number\", \"value\": 125 } or { \"type\": \"dataframe\", \"value\": pd.DataFrame({...}) } or { \"type\": \"plot\", \"value\": \"temp_chart.png\" }\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "### QUERY\n",
      " <TIME_CONTEXT>Current date: 2024-12-30</TIME_CONTEXT>\n",
      "Show me the distribution of shipment delays. /no_think\n",
      "\n",
      "At the end, declare \"result\" variable as a dictionary of type and value.\n",
      "\n",
      "\n",
      "Generate python code and return full updated code:\n",
      "\n",
      "### Note: Use only relevant table for query and do aggregation, sorting, joins and grouby through sql query```\n",
      "---\n",
      "Code Generated:\n",
      "```python\n",
      "# TODO: import the required dependencies\n",
      "import pandas as pd\n",
      "\n",
      "# Write code here\n",
      "sql_query = \"\"\"\n",
      "SELECT \n",
      "    delay_reason, \n",
      "    COUNT(*) AS count\n",
      "FROM \n",
      "    table_6619b1d3d4c59fcb9f82845d59178bfd\n",
      "GROUP BY \n",
      "    delay_reason\n",
      "ORDER BY \n",
      "    count DESC;\n",
      "\"\"\"\n",
      "\n",
      "# Execute the SQL query\n",
      "delay_distribution_df = execute_sql_query(sql_query)\n",
      "\n",
      "# Declare result var: \n",
      "result = {\n",
      "    \"type\": \"dataframe\",\n",
      "    \"value\": delay_distribution_df\n",
      "}```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show code generation step with formatted code\n",
    "if 'code_generation' in reasoning_capture.categorized_steps:\n",
    "    code_logs = reasoning_capture.categorized_steps['code_generation']\n",
    "    display_prompt = \"\"\n",
    "    duration = code_logs[-1]['elapsed_ms'] - code_logs[0]['elapsed_ms']\n",
    "    # display_prompt += code_logs[0].get('message', '') + \"\\n\" # 'Generating new code...'  command\n",
    "    prompt = reasoning_capture.extract_code_from_message(code_logs[1][\"message\"], \"using prompt:\")\n",
    "    prefix = code_logs[1][\"message\"]\n",
    "    prefix = prefix.replace(prompt, \"\")\n",
    "    display_prompt += f\"{prefix}\\n```html\\n{prompt}```\\n---\\n\" # the initial prompt\n",
    "    \n",
    "    code = reasoning_capture.extract_code_from_message(code_logs[2][\"message\"], \"code generated:\")\n",
    "    prefix = code_logs[2][\"message\"]\n",
    "    prefix = prefix.replace(code, \"\")\n",
    "    display_prompt += f\"{prefix}```python\\n{code}```\\n\" # the generated code\n",
    "    print(f\"Code Generation Step (Duration: {duration}ms):\\n{display_prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7f3329e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'timestamp': '2025-11-09T22:33:13.765689',\n",
       "  'elapsed_ms': 287,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'logger',\n",
       "  'message': 'Generating new code...',\n",
       "  'step': 'code_generation'},\n",
       " {'timestamp': '2025-11-09T22:33:13.793816',\n",
       "  'elapsed_ms': 316,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'logger',\n",
       "  'message': 'Using Prompt: <tables>\\n\\n<table dialect=\"duckdb\" table_name=\"table_6619b1d3d4c59fcb9f82845d59178bfd\" columns=\"[{\"name\": \"id\", \"type\": \"integer\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"route\", \"type\": \"string\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"warehouse\", \"type\": \"string\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"delivery_time\", \"type\": \"float\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"delay_minutes\", \"type\": \"integer\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"delay_reason\", \"type\": \"string\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"date\", \"type\": \"datetime\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"on_time\", \"type\": \"integer\", \"description\": null, \"expression\": null, \"alias\": null}]\" dimensions=\"1000x8\">\\nid,route,warehouse,delivery_time,delay_minutes,delay_reason,date,on_time\\n1,Route C,WH2,4.88,51,Customs Delay,2024-01-02,0\\n2,Route A,WH4,4.77,45,Driver Rest,2024-01-03,0\\n3,Route C,WH4,5.31,113,Traffic,2024-01-04,0\\n4,Route B,WH4,5.83,32,Minor Breakdown,2024-01-05,0\\n5,Route C,WH4,6.13,120,Traffic,2024-01-06,0\\n</table>\\n\\n\\n</tables>\\n\\nYou are already provided with the following functions that you can call:\\n<function>\\ndef execute_sql_query(sql_query: str) -> pd.Dataframe\\n    \"\"\"This method connects to the database, executes the sql query and returns the dataframe\"\"\"\\n</function>\\n\\n\\nUpdate this initial code:\\n```python\\n# TODO: import the required dependencies\\nimport pandas as pd\\n\\n# Write code here\\n\\n# Declare result var: \\ntype (possible values \"string\", \"number\", \"dataframe\", \"plot\"). Examples: { \"type\": \"string\", \"value\": f\"The highest salary is {highest_salary}.\" } or { \"type\": \"number\", \"value\": 125 } or { \"type\": \"dataframe\", \"value\": pd.DataFrame({...}) } or { \"type\": \"plot\", \"value\": \"temp_chart.png\" }\\n\\n```\\n\\n\\n\\n### QUERY\\n <TIME_CONTEXT>Current date: 2024-12-30</TIME_CONTEXT>\\nShow me the distribution of shipment delays. /no_think\\n\\nAt the end, declare \"result\" variable as a dictionary of type and value.\\n\\n\\nGenerate python code and return full updated code:\\n\\n### Note: Use only relevant table for query and do aggregation, sorting, joins and grouby through sql query',\n",
       "  'step': 'code_generation'},\n",
       " {'timestamp': '2025-11-09T22:33:16.046454',\n",
       "  'elapsed_ms': 2568,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'logger',\n",
       "  'message': 'Code Generated:\\n# TODO: import the required dependencies\\nimport pandas as pd\\n\\n# Write code here\\nsql_query = \"\"\"\\nSELECT \\n    delay_reason, \\n    COUNT(*) AS count\\nFROM \\n    table_6619b1d3d4c59fcb9f82845d59178bfd\\nGROUP BY \\n    delay_reason\\nORDER BY \\n    count DESC;\\n\"\"\"\\n\\n# Execute the SQL query\\ndelay_distribution_df = execute_sql_query(sql_query)\\n\\n# Declare result var: \\nresult = {\\n    \"type\": \"dataframe\",\\n    \"value\": delay_distribution_df\\n}',\n",
       "  'step': 'code_generation'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_capture.categorized_steps['code_generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f9a6d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'timestamp': '2025-11-09T22:33:13.477696',\n",
       "  'elapsed_ms': 0,\n",
       "  'level': 'WARNING',\n",
       "  'logger': 'semantic',\n",
       "  'message': \"Failed to register semantic dataset: create() got an unexpected keyword argument 'name'\",\n",
       "  'step': 'other'},\n",
       " {'timestamp': '2025-11-09T22:33:13.480142',\n",
       "  'elapsed_ms': 2,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'app',\n",
       "  'message': 'Loaded 1000 records from data/shipments.csv',\n",
       "  'step': 'other'},\n",
       " {'timestamp': '2025-11-09T22:33:13.507960',\n",
       "  'elapsed_ms': 30,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'app',\n",
       "  'message': 'Handling statistics request (typed)',\n",
       "  'step': 'query_understanding'},\n",
       " {'timestamp': '2025-11-09T22:33:13.509164',\n",
       "  'elapsed_ms': 31,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'logger',\n",
       "  'message': 'Question: <TIME_CONTEXT>Current date: 2024-12-30</TIME_CONTEXT>\\nShow me the distribution of shipment delays. /no_think',\n",
       "  'step': 'query_understanding'},\n",
       " {'timestamp': '2025-11-09T22:33:13.728291',\n",
       "  'elapsed_ms': 250,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'logger',\n",
       "  'message': 'Running PandasAI with litellm LLM...',\n",
       "  'step': 'other'},\n",
       " {'timestamp': '2025-11-09T22:33:13.746849',\n",
       "  'elapsed_ms': 269,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'logger',\n",
       "  'message': 'Prompt ID: 5cf367e7-0b4f-4f45-8aea-4cb024dd7ed2',\n",
       "  'step': 'other'},\n",
       " {'timestamp': '2025-11-09T22:33:13.765689',\n",
       "  'elapsed_ms': 287,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'logger',\n",
       "  'message': 'Generating new code...',\n",
       "  'step': 'code_generation'},\n",
       " {'timestamp': '2025-11-09T22:33:13.793816',\n",
       "  'elapsed_ms': 316,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'logger',\n",
       "  'message': 'Using Prompt: <tables>\\n\\n<table dialect=\"duckdb\" table_name=\"table_6619b1d3d4c59fcb9f82845d59178bfd\" columns=\"[{\"name\": \"id\", \"type\": \"integer\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"route\", \"type\": \"string\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"warehouse\", \"type\": \"string\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"delivery_time\", \"type\": \"float\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"delay_minutes\", \"type\": \"integer\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"delay_reason\", \"type\": \"string\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"date\", \"type\": \"datetime\", \"description\": null, \"expression\": null, \"alias\": null}, {\"name\": \"on_time\", \"type\": \"integer\", \"description\": null, \"expression\": null, \"alias\": null}]\" dimensions=\"1000x8\">\\nid,route,warehouse,delivery_time,delay_minutes,delay_reason,date,on_time\\n1,Route C,WH2,4.88,51,Customs Delay,2024-01-02,0\\n2,Route A,WH4,4.77,45,Driver Rest,2024-01-03,0\\n3,Route C,WH4,5.31,113,Traffic,2024-01-04,0\\n4,Route B,WH4,5.83,32,Minor Breakdown,2024-01-05,0\\n5,Route C,WH4,6.13,120,Traffic,2024-01-06,0\\n</table>\\n\\n\\n</tables>\\n\\nYou are already provided with the following functions that you can call:\\n<function>\\ndef execute_sql_query(sql_query: str) -> pd.Dataframe\\n    \"\"\"This method connects to the database, executes the sql query and returns the dataframe\"\"\"\\n</function>\\n\\n\\nUpdate this initial code:\\n```python\\n# TODO: import the required dependencies\\nimport pandas as pd\\n\\n# Write code here\\n\\n# Declare result var: \\ntype (possible values \"string\", \"number\", \"dataframe\", \"plot\"). Examples: { \"type\": \"string\", \"value\": f\"The highest salary is {highest_salary}.\" } or { \"type\": \"number\", \"value\": 125 } or { \"type\": \"dataframe\", \"value\": pd.DataFrame({...}) } or { \"type\": \"plot\", \"value\": \"temp_chart.png\" }\\n\\n```\\n\\n\\n\\n### QUERY\\n <TIME_CONTEXT>Current date: 2024-12-30</TIME_CONTEXT>\\nShow me the distribution of shipment delays. /no_think\\n\\nAt the end, declare \"result\" variable as a dictionary of type and value.\\n\\n\\nGenerate python code and return full updated code:\\n\\n### Note: Use only relevant table for query and do aggregation, sorting, joins and grouby through sql query',\n",
       "  'step': 'code_generation'},\n",
       " {'timestamp': '2025-11-09T22:33:16.046454',\n",
       "  'elapsed_ms': 2568,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'logger',\n",
       "  'message': 'Code Generated:\\n# TODO: import the required dependencies\\nimport pandas as pd\\n\\n# Write code here\\nsql_query = \"\"\"\\nSELECT \\n    delay_reason, \\n    COUNT(*) AS count\\nFROM \\n    table_6619b1d3d4c59fcb9f82845d59178bfd\\nGROUP BY \\n    delay_reason\\nORDER BY \\n    count DESC;\\n\"\"\"\\n\\n# Execute the SQL query\\ndelay_distribution_df = execute_sql_query(sql_query)\\n\\n# Declare result var: \\nresult = {\\n    \"type\": \"dataframe\",\\n    \"value\": delay_distribution_df\\n}',\n",
       "  'step': 'code_generation'},\n",
       " {'timestamp': '2025-11-09T22:33:16.105197',\n",
       "  'elapsed_ms': 2627,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'logger',\n",
       "  'message': 'Validating code requirements...',\n",
       "  'step': 'code_validation'},\n",
       " {'timestamp': '2025-11-09T22:33:16.127325',\n",
       "  'elapsed_ms': 2649,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'logger',\n",
       "  'message': 'Code validation successful.',\n",
       "  'step': 'code_validation'},\n",
       " {'timestamp': '2025-11-09T22:33:16.146538',\n",
       "  'elapsed_ms': 2668,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'logger',\n",
       "  'message': 'Cleaning the generated code...',\n",
       "  'step': 'other'},\n",
       " {'timestamp': '2025-11-09T22:33:16.166398',\n",
       "  'elapsed_ms': 2688,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'logger',\n",
       "  'message': 'Executing code: import pandas as pd\\nsql_query = \"\"\"\\nSELECT \\n    delay_reason, \\n    COUNT(*) AS count\\nFROM \\n    table_6619b1d3d4c59fcb9f82845d59178bfd\\nGROUP BY \\n    delay_reason\\nORDER BY \\n    count DESC;\\n\"\"\"\\ndelay_distribution_df = execute_sql_query(sql_query)\\nresult = {\\'type\\': \\'dataframe\\', \\'value\\': delay_distribution_df}',\n",
       "  'step': 'code_execution'},\n",
       " {'timestamp': '2025-11-09T22:33:16.369150',\n",
       "  'elapsed_ms': 2891,\n",
       "  'level': 'INFO',\n",
       "  'logger': 'logger',\n",
       "  'message': 'Response generated successfully.',\n",
       "  'step': 'response_generation'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_capture.reasoning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a83460e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'code_execution'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_capture._categorize_step(\"Executing code: print('Hello World')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ce6cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasai.core.response import DataFrameResponse, NumberResponse, ChartResponse, StringResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2476edc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseResponse.to_json() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mDataFrameResponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: BaseResponse.to_json() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "DataFrameResponse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4203293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'ðŸ¤–        delay_reason  count\\n0              None    170\\n1           Traffic    157\\n2       Driver Rest    145\\n3  Mechanical Issue    143\\n4           Weather    137\\n5   Minor Breakdown    133\\n6     Customs Delay    115',\n",
       " 'chart': None,\n",
       " 'intent': 'general',\n",
       " 'metadata': {'data_type': 'text',\n",
       "  'raw': DataFrameResponse(type='dataframe', value=       delay_reason  count\n",
       "  0              None    170\n",
       "  1           Traffic    157\n",
       "  2       Driver Rest    145\n",
       "  3  Mechanical Issue    143\n",
       "  4           Weather    137\n",
       "  5   Minor Breakdown    133\n",
       "  6     Customs Delay    115)},\n",
       " 'timestamp': datetime.datetime(2025, 11, 6, 8, 53, 7, 296382),\n",
       " 'success': True,\n",
       " 'error': None,\n",
       " 'data_type': 'text',\n",
       " 'raw_result': DataFrameResponse(type='dataframe', value=       delay_reason  count\n",
       " 0              None    170\n",
       " 1           Traffic    157\n",
       " 2       Driver Rest    145\n",
       " 3  Mechanical Issue    143\n",
       " 4           Weather    137\n",
       " 5   Minor Breakdown    133\n",
       " 6     Customs Delay    115)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dde06c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GeneralResponse' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhermes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseResponse\n\u001b[0;32m----> 3\u001b[0m response\u001b[38;5;241m.\u001b[39mchart\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, BaseResponse) \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchart \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchart\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, BaseResponse) \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchart:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mchart\u001b[38;5;241m.\u001b[39mpath)\n",
      "File \u001b[0;32m~/anaconda3/envs/phitha1/lib/python3.11/site-packages/pydantic/main.py:991\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GeneralResponse' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "from hermes.models import BaseResponse\n",
    "\n",
    "response.chart.path if isinstance(response, BaseResponse) and response.chart else response.get(\"chart\")\n",
    "if isinstance(response, BaseResponse):\n",
    "    if response.chart:\n",
    "        return response.chart.path\n",
    "else:\n",
    "        return response.get(\"chart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c07c364",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'pydantic_core._pydantic_core.ValidationInfo' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/data1/workspaces/phitha1/Hermes/src/hermes/app.py:215\u001b[0m, in \u001b[0;36m_handle_prediction_chat\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# Validate and structure data\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m metrics \u001b[38;5;241m=\u001b[39m MetricsData(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetrics_dict)\n\u001b[1;32m    216\u001b[0m prediction \u001b[38;5;241m=\u001b[39m PredictionData(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpred_dict)\n",
      "File \u001b[0;32m~/anaconda3/envs/phitha1/lib/python3.11/site-packages/pydantic/main.py:253\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    252\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_validator__\u001b[38;5;241m.\u001b[39mvalidate_python(data, self_instance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for PredictionData\nconfidence_interval\n  Input should be a valid dictionary [type=dict_type, input_value=(53.802953910622996, 54.96932568710414), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.11/v/dict_type",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mhermes_app\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_prediction_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPredict the delay rate for next week.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/workspaces/phitha1/Hermes/src/hermes/app.py:246\u001b[0m, in \u001b[0;36m_handle_prediction_chat\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PredictionResponse(\n\u001b[1;32m    235\u001b[0m         text\u001b[38;5;241m=\u001b[39mresponse_text,\n\u001b[1;32m    236\u001b[0m         intent\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m         }\n\u001b[1;32m    243\u001b[0m     )\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 246\u001b[0m     logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PredictionResponse(\n\u001b[1;32m    248\u001b[0m         text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâŒ **Prediction Error:** \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure your data includes columns: date, delay_minutes, route, and warehouse.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    249\u001b[0m         intent\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(e)}\n\u001b[1;32m    253\u001b[0m     )\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/data1/workspaces/phitha1/Hermes/src/hermes/models.py:148\u001b[0m, in \u001b[0;36mPredictionResponse.populate_metadata\u001b[0;34m(cls, v, values)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;129m@field_validator\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpopulate_metadata\u001b[39m(\u001b[38;5;28mcls\u001b[39m, v: Dict[\u001b[38;5;28mstr\u001b[39m, Any], validation_info: ValidationInfo) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;66;03m# Auto-populate metadata from metrics and prediction\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m     data \u001b[38;5;241m=\u001b[39m validation_info\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    150\u001b[0m         v[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdict()\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'pydantic_core._pydantic_core.ValidationInfo' is not iterable"
     ]
    }
   ],
   "source": [
    "response = hermes_app._handle_prediction_chat(\"Predict the delay rate for next week.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca929403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hermes.config import CHARTS_DIR, DATA_DIR, QUESTIONS_FILE, SHIPMENTS_FILE, llm\n",
    "from hermes.visualizer import HermesVisualizer\n",
    "visualizer = HermesVisualizer(charts_dir=\"/data1/workspaces/phitha1/Hermes/exports/charts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01ae23cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data1/workspaces/phitha1/Hermes/exports/charts/temp_chart_a22db8c9-d29c-4c67-a3e0-c664fbeacf8c.png'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizer.get_latest_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23c9a5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hermes.ui_agent import HermesAgentTools, extract_response_components\n",
    "tools = HermesAgentTools(hermes_app)\n",
    "# result = tools.analyze_query(\"Show delay reason counts for WH1.\", \"general\")\n",
    "result = tools.analyze_query(\"How many shipments from WH3 had delays?\", \"statistics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8121b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '',\n",
       " 'chart': None,\n",
       " 'intent': 'statistics',\n",
       " 'data_type': 'number',\n",
       " 'raw_result': NumberResponse(type='number', value=203),\n",
       " 'metadata': {'total_shipments': 1000,\n",
       "  'delayed_shipments': 830,\n",
       "  'on_time_shipments': 170,\n",
       "  'on_time_rate': 0.17,\n",
       "  'delay_rate': 0.83,\n",
       "  'avg_delay_minutes': 63.59518072289157,\n",
       "  'median_delay_minutes': 67.0,\n",
       "  'avg_delivery_time': 5.49323,\n",
       "  'date_range': '2024-01-01 to 2024-12-30'},\n",
       " 'timestamp': datetime.datetime(2025, 11, 7, 15, 32, 34, 4285),\n",
       " 'success': True,\n",
       " 'error': None,\n",
       " 'stats': StatsSummary(total_shipments=1000, delayed_shipments=830, on_time_shipments=170, on_time_rate=0.17, delay_rate=0.83, avg_delay_minutes=63.59518072289157, median_delay_minutes=67.0, avg_delivery_time=5.49323, date_range='2024-01-01 to 2024-12-30'),\n",
       " 'data_preview': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"response_model\"].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e43853fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '',\n",
       " 'dataframe': None,\n",
       " 'number': 203.0,\n",
       " 'chart_path': None,\n",
       " 'metrics': None,\n",
       " 'recommendations': None,\n",
       " 'stats': {'total_shipments': 1000,\n",
       "  'delayed_shipments': 830,\n",
       "  'on_time_rate': 0.83,\n",
       "  'avg_delay_minutes': 63.59518072289157},\n",
       " 'data_type': 'number'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_response_components(result[\"response_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7e4ed49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '', 'dataframe': None, 'number': 203.0, 'chart_path': None, 'metrics': None, 'recommendations': None, 'stats': {'total_shipments': 1000, 'delayed_shipments': 830, 'on_time_rate': 0.83, 'avg_delay_minutes': 63.59518072289157}, 'data_type': 'number'}\n"
     ]
    }
   ],
   "source": [
    "if extract_response_components(result[\"response_model\"])[\"data_type\"] == \"number\" and extract_response_components(result[\"response_model\"])[\"number\"] is not None:\n",
    "    print(extract_response_components(result[\"response_model\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56c8a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\n\\n</think>\\n\\n{\"intent\": \"statistics\", \"confidence\": 0.85}'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hermes.prompts import PROMPT_TEMPLATES\n",
    "from hermes.llm import ask_llm\n",
    "\n",
    "prompt = PROMPT_TEMPLATES['classification_intent'].format(query=\"List shipments in April with delay_minutes > 30.\")\n",
    "ask_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d335103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/shipments.csv\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eecc312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "<string>:3: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "<string>:4: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "<string>:1: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "<string>:3: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "<string>:4: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "questions = pd.read_csv(\"./data/questions.csv\")\n",
    "\n",
    "answers = []\n",
    "for i, row in questions.iterrows():\n",
    "    exec_locals = {\"df\": df, \"pd\": pd}\n",
    "    exec(row[\"code_concise\"], {}, exec_locals)\n",
    "    answers.append(exec_locals.get(\"result\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4d63faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>code_concise</th>\n",
       "      <th>code_verbose</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>405</td>\n",
       "      <td>Predict next week's delay rate using historical averages. (count only)</td>\n",
       "      <td>df['date']=pd.to_datetime(df['date']); last_28=df[df['date']&gt;df['date'].max()-pd.Timedelta(days=27)]; result = (last_28['delay_minutes']&gt;0).mean()</td>\n",
       "      <td>df['date']=pd.to_datetime(df['date'])\\nmax_date = df['date'].max()\\nlast_28 = df[df['date'] &gt; max_date - pd.Timedelta(days=27)]\\nresult = (last_28['delay_minutes'] &gt; 0).mean()\\n</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>What is the total delay time across all shipments?</td>\n",
       "      <td>result = df['delay_minutes'].sum()</td>\n",
       "      <td># total delay minutes across dataset\\nresult = df['delay_minutes'].sum()\\n</td>\n",
       "      <td>52784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>136</td>\n",
       "      <td>How many shipments occurred on Thursdays?</td>\n",
       "      <td>result = {'shape': df.shape, 'columns': list(df.columns)}</td>\n",
       "      <td>result = {'shape': df.shape, 'columns': list(df.columns), 'sample': df.head(3).to_dict(orient='records')}\\n</td>\n",
       "      <td>{'shape': (1000, 7), 'columns': ['id', 'route', 'warehouse', 'delivery_time', 'delay_minutes', 'delay_reason', 'date']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>95</td>\n",
       "      <td>Which warehouse had the most shipments in May?</td>\n",
       "      <td>result = {'shape': df.shape, 'columns': list(df.columns)}</td>\n",
       "      <td>result = {'shape': df.shape, 'columns': list(df.columns), 'sample': df.head(3).to_dict(orient='records')}\\n</td>\n",
       "      <td>{'shape': (1000, 7), 'columns': ['id', 'route', 'warehouse', 'delivery_time', 'delay_minutes', 'delay_reason', 'date']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>Which week had the most deliveries?</td>\n",
       "      <td>df['date']=pd.to_datetime(df['date']); result = df.groupby(df['date'].dt.isocalendar().week)['id'].count().idxmax()</td>\n",
       "      <td>df['date']=pd.to_datetime(df['date'])\\n# week number with most deliveries\\nresult = df.groupby(df['date'].dt.isocalendar().week)['id'].count().idxmax()\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  \\\n",
       "134  405   \n",
       "9     10   \n",
       "97   136   \n",
       "77    95   \n",
       "35    36   \n",
       "\n",
       "                                                                   question  \\\n",
       "134  Predict next week's delay rate using historical averages. (count only)   \n",
       "9                        What is the total delay time across all shipments?   \n",
       "97                                How many shipments occurred on Thursdays?   \n",
       "77                           Which warehouse had the most shipments in May?   \n",
       "35                                      Which week had the most deliveries?   \n",
       "\n",
       "                                                                                                                                           code_concise  \\\n",
       "134  df['date']=pd.to_datetime(df['date']); last_28=df[df['date']>df['date'].max()-pd.Timedelta(days=27)]; result = (last_28['delay_minutes']>0).mean()   \n",
       "9                                                                                                                    result = df['delay_minutes'].sum()   \n",
       "97                                                                                            result = {'shape': df.shape, 'columns': list(df.columns)}   \n",
       "77                                                                                            result = {'shape': df.shape, 'columns': list(df.columns)}   \n",
       "35                                  df['date']=pd.to_datetime(df['date']); result = df.groupby(df['date'].dt.isocalendar().week)['id'].count().idxmax()   \n",
       "\n",
       "                                                                                                                                                                          code_verbose  \\\n",
       "134  df['date']=pd.to_datetime(df['date'])\\nmax_date = df['date'].max()\\nlast_28 = df[df['date'] > max_date - pd.Timedelta(days=27)]\\nresult = (last_28['delay_minutes'] > 0).mean()\\n   \n",
       "9                                                                                                           # total delay minutes across dataset\\nresult = df['delay_minutes'].sum()\\n   \n",
       "97                                                                         result = {'shape': df.shape, 'columns': list(df.columns), 'sample': df.head(3).to_dict(orient='records')}\\n   \n",
       "77                                                                         result = {'shape': df.shape, 'columns': list(df.columns), 'sample': df.head(3).to_dict(orient='records')}\\n   \n",
       "35                           df['date']=pd.to_datetime(df['date'])\\n# week number with most deliveries\\nresult = df.groupby(df['date'].dt.isocalendar().week)['id'].count().idxmax()\\n   \n",
       "\n",
       "                                                                                                                      answer  \n",
       "134                                                                                                                 0.833333  \n",
       "9                                                                                                                      52784  \n",
       "97   {'shape': (1000, 7), 'columns': ['id', 'route', 'warehouse', 'delivery_time', 'delay_minutes', 'delay_reason', 'date']}  \n",
       "77   {'shape': (1000, 7), 'columns': ['id', 'route', 'warehouse', 'delivery_time', 'delay_minutes', 'delay_reason', 'date']}  \n",
       "35                                                                                                                         1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"max_colwidth\", None)\n",
    "questions[\"answer\"] = answers\n",
    "questions.sample(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phitha1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
